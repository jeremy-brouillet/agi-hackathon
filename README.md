Has your team ever wanted to share data, but just the general picture rather than specifics? At a large organization, would one division want to give soft access to another, but not leak sensitive or personally identifying information? This project explores this possibility, both from the building of the application, and also testing the system for vulnerbilities. As it turns out, the vulnerbilities are definitely there.

This project was created for the 1-day AGI House Hackathon. The purpose of the hackathon was to create and break LLM apps. This project won the Break category.

Getting started with the repository:
The bulk of it is in the Soft access with LLMs Jupyter Notebook. Additional data that is accessed by retrieval-augmented generation is in the data folder. 

To run, set up a virtual environment, install from the requirements.txt, create a .env file with your OpenAI API key (see .env_example), and run the the notebook.

The data contained within was generated by GPT-4, all names are fictional, the data is just meant to serve as an illustrative example and should not be relied upon as factual information.